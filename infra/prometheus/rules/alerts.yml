# =============================================================================
# Prometheus Alerting Rules
# Crypto Sentiment API
# =============================================================================

groups:
  # ===========================================================================
  # API Health Alerts
  # ===========================================================================
  - name: api_health
    interval: 30s
    rules:
      - alert: APIDown
        expr: up{job="sentiment-api"} == 0
        for: 1m
        labels:
          severity: critical
          team: platform
        annotations:
          summary: "Sentiment API is down"
          description: "{{ $labels.instance }} has been down for more than 1 minute."
          runbook_url: "https://docs.sentiment-api.io/runbooks/api-down"

      - alert: HighErrorRate
        expr: |
          sum(rate(http_requests_total{job="sentiment-api",status=~"5.."}[5m]))
          / sum(rate(http_requests_total{job="sentiment-api"}[5m])) > 0.05
        for: 5m
        labels:
          severity: critical
          team: platform
        annotations:
          summary: "High error rate detected"
          description: "Error rate is {{ $value | humanizePercentage }} over the last 5 minutes."

      - alert: HighLatency
        expr: |
          histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{job="sentiment-api"}[5m])) by (le)) > 1
        for: 5m
        labels:
          severity: warning
          team: platform
        annotations:
          summary: "High API latency detected"
          description: "P95 latency is {{ $value | humanizeDuration }} over the last 5 minutes."

      - alert: HighMemoryUsage
        expr: |
          process_resident_memory_bytes{job="sentiment-api"}
          / on(instance) node_memory_MemTotal_bytes > 0.85
        for: 10m
        labels:
          severity: warning
          team: platform
        annotations:
          summary: "High memory usage on API instance"
          description: "{{ $labels.instance }} memory usage is {{ $value | humanizePercentage }}."

  # ===========================================================================
  # SLA Alerts
  # ===========================================================================
  - name: sla_alerts
    interval: 1m
    rules:
      - alert: SLAAvailabilityBreach
        expr: |
          1 - (
            sum(rate(http_requests_total{job="sentiment-api",status=~"5.."}[1h]))
            / sum(rate(http_requests_total{job="sentiment-api"}[1h]))
          ) < 0.999
        for: 5m
        labels:
          severity: critical
          team: platform
          sla: availability
        annotations:
          summary: "SLA availability breach"
          description: "Availability is {{ $value | humanizePercentage }}, below 99.9% SLA target."

      - alert: SLALatencyBreach
        expr: |
          histogram_quantile(0.99, sum(rate(http_request_duration_seconds_bucket{job="sentiment-api"}[1h])) by (le)) > 0.5
        for: 5m
        labels:
          severity: warning
          team: platform
          sla: latency
        annotations:
          summary: "SLA latency breach"
          description: "P99 latency is {{ $value | humanizeDuration }}, above 500ms SLA target."

  # ===========================================================================
  # Rate Limiting Alerts
  # ===========================================================================
  - name: rate_limiting
    interval: 30s
    rules:
      - alert: HighRateLimitExceeded
        expr: |
          sum(rate(rate_limit_exceeded_total{job="sentiment-api"}[5m])) by (tier) > 10
        for: 5m
        labels:
          severity: warning
          team: platform
        annotations:
          summary: "High rate limit exceeded events for {{ $labels.tier }} tier"
          description: "{{ $value }} rate limit exceeded events per second for {{ $labels.tier }} tier."

      - alert: EnterpriseTierRateLimitApproaching
        expr: |
          rate_limit_tokens_remaining{job="sentiment-api",tier="enterprise"}
          / rate_limit_tokens_total{job="sentiment-api",tier="enterprise"} < 0.1
        for: 10m
        labels:
          severity: warning
          team: sales
        annotations:
          summary: "Enterprise customer approaching rate limit"
          description: "Enterprise client {{ $labels.client_id }} has used 90%+ of their rate limit."

  # ===========================================================================
  # Data Source Alerts
  # ===========================================================================
  - name: data_sources
    interval: 1m
    rules:
      - alert: DataSourceDown
        expr: datasource_health{job="sentiment-api"} == 0
        for: 5m
        labels:
          severity: warning
          team: data
        annotations:
          summary: "Data source {{ $labels.source }} is down"
          description: "{{ $labels.source }} has been unavailable for more than 5 minutes."

      - alert: AllDataSourcesDown
        expr: sum(datasource_health{job="sentiment-api"}) == 0
        for: 2m
        labels:
          severity: critical
          team: data
        annotations:
          summary: "All data sources are down"
          description: "No data sources are currently available. Sentiment data will become stale."

      - alert: DataSourceHighLatency
        expr: |
          histogram_quantile(0.95, sum(rate(datasource_request_duration_seconds_bucket{job="sentiment-api"}[5m])) by (le, source)) > 5
        for: 10m
        labels:
          severity: warning
          team: data
        annotations:
          summary: "High latency for data source {{ $labels.source }}"
          description: "{{ $labels.source }} P95 latency is {{ $value | humanizeDuration }}."

      - alert: DataSourceRateLimitCritical
        expr: datasource_rate_limit_usage{job="sentiment-api"} > 0.95
        for: 5m
        labels:
          severity: critical
          team: data
        annotations:
          summary: "Data source {{ $labels.source }} rate limit critical"
          description: "{{ $labels.source }} has used {{ $value | humanizePercentage }} of its rate limit."

      - alert: FallbackActivated
        expr: increase(datasource_fallback_activated_total{job="sentiment-api"}[5m]) > 0
        labels:
          severity: info
          team: data
        annotations:
          summary: "Fallback activated for {{ $labels.source }}"
          description: "Switched to {{ $labels.fallback_provider }} for {{ $labels.source }}."

  # ===========================================================================
  # Pipeline Alerts
  # ===========================================================================
  - name: pipeline
    interval: 30s
    rules:
      - alert: PipelineProcessingLag
        expr: |
          kafka_consumergroup_lag{job="kafka",topic=~"sentiment.*"} > 10000
        for: 5m
        labels:
          severity: warning
          team: data
        annotations:
          summary: "High processing lag on {{ $labels.topic }}"
          description: "Consumer lag is {{ $value }} messages on {{ $labels.topic }}."

      - alert: PipelineHighErrorRate
        expr: |
          rate(pipeline_items_failed_total{job="sentiment-api"}[5m])
          / rate(pipeline_items_processed_total{job="sentiment-api"}[5m]) > 0.1
        for: 10m
        labels:
          severity: warning
          team: data
        annotations:
          summary: "High pipeline error rate"
          description: "{{ $value | humanizePercentage }} of pipeline items are failing."

      - alert: SentimentDataStale
        expr: |
          time() - max(sentiment_last_processed_timestamp{job="sentiment-api"}) > 300
        for: 5m
        labels:
          severity: warning
          team: data
        annotations:
          summary: "Sentiment data is stale"
          description: "No new sentiment data processed in the last 5 minutes."

  # ===========================================================================
  # Infrastructure Alerts
  # ===========================================================================
  - name: infrastructure
    interval: 30s
    rules:
      - alert: RedisDown
        expr: up{job="redis"} == 0
        for: 1m
        labels:
          severity: critical
          team: platform
        annotations:
          summary: "Redis is down"
          description: "Redis instance is unavailable. Caching and rate limiting affected."

      - alert: RedisHighMemory
        expr: |
          redis_memory_used_bytes{job="redis"}
          / redis_memory_max_bytes{job="redis"} > 0.9
        for: 10m
        labels:
          severity: warning
          team: platform
        annotations:
          summary: "Redis memory usage critical"
          description: "Redis is using {{ $value | humanizePercentage }} of available memory."

      - alert: PostgresDown
        expr: up{job="postgres"} == 0
        for: 1m
        labels:
          severity: critical
          team: platform
        annotations:
          summary: "PostgreSQL/TimescaleDB is down"
          description: "Database is unavailable. All persistence operations will fail."

      - alert: PostgresHighConnections
        expr: |
          pg_stat_activity_count{job="postgres",state="active"}
          / pg_settings_max_connections{job="postgres"} > 0.8
        for: 10m
        labels:
          severity: warning
          team: platform
        annotations:
          summary: "PostgreSQL connection pool near capacity"
          description: "{{ $value | humanizePercentage }} of max connections in use."

      - alert: KafkaDown
        expr: up{job="kafka"} == 0
        for: 1m
        labels:
          severity: critical
          team: platform
        annotations:
          summary: "Kafka is down"
          description: "Kafka broker is unavailable. Event streaming affected."

      - alert: KafkaHighLag
        expr: |
          sum(kafka_consumergroup_lag{job="kafka"}) by (consumergroup) > 100000
        for: 10m
        labels:
          severity: warning
          team: platform
        annotations:
          summary: "High Kafka consumer lag"
          description: "Consumer group {{ $labels.consumergroup }} has {{ $value }} messages lag."

  # ===========================================================================
  # Sentiment Anomaly Alerts
  # ===========================================================================
  - name: sentiment_anomalies
    interval: 1m
    rules:
      - alert: ExtremeSentimentShift
        expr: |
          abs(
            avg_over_time(sentiment_score{job="sentiment-api"}[10m])
            - avg_over_time(sentiment_score{job="sentiment-api"}[1h] offset 10m)
          ) > 0.5
        for: 5m
        labels:
          severity: info
          team: analytics
        annotations:
          summary: "Extreme sentiment shift detected for {{ $labels.asset }}"
          description: "Sentiment for {{ $labels.asset }} shifted by {{ $value }} in the last hour."

      - alert: FearGreedExtreme
        expr: |
          sentiment_fear_greed_index{job="sentiment-api"} < 10
          or sentiment_fear_greed_index{job="sentiment-api"} > 90
        for: 30m
        labels:
          severity: info
          team: analytics
        annotations:
          summary: "Fear & Greed Index at extreme level"
          description: "Market Fear & Greed Index is at {{ $value }}."

      - alert: MentionVolumeSpike
        expr: |
          rate(sentiment_mentions_total{job="sentiment-api"}[10m])
          / rate(sentiment_mentions_total{job="sentiment-api"}[1h] offset 10m) > 3
        for: 5m
        labels:
          severity: info
          team: analytics
        annotations:
          summary: "Mention volume spike for {{ $labels.asset }}"
          description: "{{ $labels.asset }} mentions are {{ $value }}x normal volume."

  # ===========================================================================
  # Security Alerts
  # ===========================================================================
  - name: security
    interval: 30s
    rules:
      - alert: HighAuthFailures
        expr: |
          sum(rate(auth_failures_total{job="sentiment-api"}[5m])) > 10
        for: 5m
        labels:
          severity: warning
          team: security
        annotations:
          summary: "High authentication failure rate"
          description: "{{ $value }} auth failures per second detected."

      - alert: SuspiciousAPIActivity
        expr: |
          sum(rate(http_requests_total{job="sentiment-api"}[1m])) by (client_id) > 1000
        for: 1m
        labels:
          severity: warning
          team: security
        annotations:
          summary: "Suspicious API activity from {{ $labels.client_id }}"
          description: "Client {{ $labels.client_id }} is making {{ $value }} requests per second."

      - alert: InvalidAPIKeyAttempts
        expr: |
          sum(rate(invalid_api_key_total{job="sentiment-api"}[5m])) > 5
        for: 5m
        labels:
          severity: warning
          team: security
        annotations:
          summary: "High invalid API key attempts"
          description: "{{ $value }} invalid API key attempts per second."
